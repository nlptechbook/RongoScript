<img src="https://github.com/nlptechbook/RongoScript/blob/main/Icon/moai.jpg" align="left" width="100px"/>

# RongoScript: Движок для бота на базе трансформера 
<sub>Рисунок Константина Лупанова</sub> 
<br clear="left"/>

[Switch to the English version](https://github.com/nlptechbook/RongoScript/)

RongoScript - это программный продукт, предназначенный для использования в качестве движка бота, использующего естественный язык для коммуникации с пользователем. Концепция схожа с той, что лежит в основе гугловского DialogFlow: система обрабатывает и классифицирует реплики пользователя, реагируя предопределенным способом.  

Упрощенная версия движка используется в нашем демо боте @RuRongoBot в Telegram.  Бот позволяет вам протестировать движок на ваших данных или использовать предоставленный набор. Подробнее об этом ниже в секции Демо бот в Telegram. 

Нижеследующие секции дают технологический обзор используемых в движке компонентов.

## Использование трансформера для классификации фраз пользователя

Идея в том, что бот получает реплику (команду/вопрос) от пользователя на естественном языке и классифицирует его к определенному интенту, чтобы затем выполнить соответсвующую команду или сгенерировать адекватный ответ. Для решения задачи классификации использует нейросеть на базе трансформера. Когда интент идентифицирован, выполняется закрепленное за ним действие. Например, выполняется закрепленная функция с посланными в неё параметрами, извлеченными из пользовательской реплики, или - в самом простом случае - посылается предопределенный ответ.  

## Обработка текстовых данных перед  подачей в трансформер

Перед тем как входные фразы подаются в трансформер (как для обучения, так и для классификации)  они проходят предварительную обработку. Следующие несколько секций описывают основные этапы этой обработки.  

### Лемматизация 

Лемматизация – это процесс сведение различных форм слова (токена) к их лемме. Лемма является базовой формой слова. Для ясности, о лемме можно думать как о форме в которой слово появляется в словаре. Например, лемма для токена «доброго» — «добрый». 

Пример не случаен. Допустим вы создаете список приветственных фраз, одной из которых пользователь предположительно начнет разговор с ботом. Вы, конечно, включите в такой список «здравствуйте», «добрый день», и т.д. Это работает неплохо, но вот появляется кто-то и приветствует бота фразой «доброго дня». Ожидаемо, при отсутствии предварительной лемматизации, эмбединг этой фразы будет отличаться от эмбедингов известных классификатору фраз из списка, что не позволит ему правильно классифицировать новую фразу - по крайней мере, сделать это с высокой степенью уверенности. 

Однако, если в вашей системе проводится предварительная лемматизация, то фраза «доброго дня» - перед тем как быть посланной в классификатор - будет автоматически конвертирована в ту, что уже есть в списке: «добрый день». При работе с русским языком, лемматизация особенно актуальна, так как мы обычно имеем дело с большим количеством форм слова, порожденных разнообразием падежных, числовых, и родовых окончаний. С другой стороны, что важно, для нейросети как правило не требуется брать во внимание окончания слов, чтобы корректно классифицировать смысл фразы. 

Обобщая, лемматизация сокращает количество обучающих фраз и, соответственно,  объем  словаря, необходимого для приемлемой работы классификатора.   

### NER обработка 

NER (распознавание именованных сущностей) обработка производится в два этапа: Во-первых, найденные в тексте именованные сущности (имена людей, названия организаций, городов, даты, и т.д) сохраняются в словаре, который затем может быть послан в функцию обработки (при наличии таковой для данного класса). 

Следующий этап включает замену именованных сущностей на соответствующие им метки. Так, к примеру, Москва будет заменена на GPE, а, скажем, DeepPavlov на ORG. Это способствует обобщению данных, улучшая таким образом предиктивную аккуратность классификатора.  Например, фразы:

> Какая погода будет завтра в Москве 

и  

> Какая погода будет послезавтра в Сочи 

сведутся к одной и той же фразе:

> Какая погода будет DATE в GPE

Как следствие, позволяя классификатору однозначно идентифицировать все подобные фразы. В тоже время, как отмечалось выше, извлеченные ранее конкретные названия могут быть переданы в обработку, для генерации ответа специфичного к данному конкретному запросу.
 
### Эмбединг на основе синтаксических связей вместо классического позиционного

В RongoScript мы экспериментируем с технологиями. Так наряду с классическим позиционным эмбедингом
в модели трансформера, мы используем эмбединг на основе синтаксических связей. В последнем случае, слова нумеруются исходя из того на каком уровне в дереве синтаксических зависимостей предложения они находятся. Так, сказуемое будет находиться на самом верхнем уровне в синтаксическом дереве. На уровень ниже в типичном предложении располагаются такие части речи как  подлежащее и дополнение. То есть, наиболее значимые слова предложения будут находиться на более высоких уровнях дерева синтаксических зависимостей, обеспечивая своего рода сортировку слов по их значимости. При этом интересно, что для дерева синтаксических зависимостей позиционное положение слов в предложении не имеет значения. Так, например, фраза: 

> Вижу я, что получилось 

будет эквивалентна фразе: 

> Я вижу, что получилось

Так как, несмотря на то, что подлежащее и сказуемое имеют разные позиции в этих предложениях, они по-прежнему представлены одними и теми же словами. 

## Использование контекста беседы созданного предыдущими фразами

Еще одна идея, над которой мы работаем, — научить трансформер делать интерпретации, основанные не только на найденных в введенной фразе словах, но и на контексте всей беседы, чтобы он мог «понимать» значение обрабатываемой фразы в зависимости от контекста. 

В то время как диалог по мере продолжения уточняет свой контекст, контекст помогает прояснить значение фраз в диалоге. Иногда вы не можете понять точное значение высказывания без контекста диалога. В качестве примера, возьмем следующее высказывание:

> Я хочу зеленое

Понять о чем идет речь без контекста невозможно. Предыдущая фраза могла бы помочь.  Например, предыдущее высказывание может быть таким:

> Какое яблоко ты хочешь?

Как видите, самое важное слово в этом предыдущем высказывании — с точки зрения понимания смысла следующего высказывания — яблоко. Таким образом, нам не нужно передавать все предыдущее высказывание для анализа в трансформер: достаточно одного извлеченного из высказывания слова. Вы можете задаться вопросом, как определить это самое важное слово (или группу наиболее важных слов в высказывании). Короткий ответ — с помощью анализа синтаксических зависимостей.

## Демо бот в Telegram 

К данному моменту у вас мог возникнуть вопрос: где можно посмотреть как это всё работает. Мы создали демонстрационной бот @RuRongoBot в Telegram, который использует RongoScript. Бот состоит из следующих компонентов: 

- Интерфейс взаимодействия с пользователем посредством текстовых сообщений в Telegram
- Нейросеть на базе трансформера для классификации пользовательских сообщений 
- Система обработки классифицированных пользовательских сообщений с генерацией ответов

Для того, чтобы бот мог начать отвечать на ваши вопросы, вам необходимо сконфигурировать RongoScript лежащий в его основе. Для этого нужно решить две задачи:  во-первых, натренировать нейросеть трансформера на конкретных вопрос/ответ парах и, во-вторых, сконфигурировать систему генерации ответов под эти кокретные данные. Обе задачи решаются одним единственным вашим действием: запуском команды /train_faq (если вы хотите использовать тренировочный набор в нашем faq.json), или загрузкой вашего json файла с вашими данными, но обязательно с той же структурой что наш faq.json. 

В обоих случаях код обработает каждую запись в json файле, и создаст соответствующие тренировочные пары. Для каждой записи в файле может быть сгенерированна одна или больше тренировочных пар, по количеству реплик в поле utterance записи. Процесс тренировки нейросети запускается следом автоматически. Получив сообщение: Готово! Вы можете начать тестирование, вводя вопросы из тренировочного набора (не обязательно слово в слово). 

Если вы изучите наш faq.json файл, вы найдете там запись с полем action установленным в конкретное значение, а именно get_news. Это имя функции, которая будет запущена, если пользователь поинтересуется новостями о какой-либо известной компании. Так как поле ner в этой записи установлено в true, из пользовательской реплики также будет извлечена именнованная сущность (ожидается название компании). Мы включили это как пример записи с обработчиком, когда пользовательская реплика классифицированная к классу в записи обрабатывается с помощью функции для генерации ответа.     

К примеру, на фразу: "Свежие новости о DeepPavlov" 11-го мая был получен такой ответ: 

> '2022-04-22T08:41:41Z'  
> Российское программное обеспечение в области искусственного интеллекта готово замещать иностранные аналоги – платформа iPavlov уже переводит работу своих цифровых ассистентов на собственное ядро, рассказал директор по разработке прикладного программного обесп…
https://vz.ru/news/2022/4/22/1155067.html

> '2022-04-11T07:25:12Z'  
> В задачах распознаваниях речи при переводе аудио в текст есть дополнительные этапы, делающие этот текст более человекочитаемым. Например, предложение "привет хабр сегодня мы сделаем двадцать шесть моделей по распознаванию голоса" будет выглядеть лучше в таком…
https://habr.com/ru/company/ods/blog/660041/#post-content-body 

В реальном проекте вы можете задать намного больше классов с обработчиком.

> **Warning**
> Бот может работать неустойчиво, ввиду того, что запушен не на выделенном сервере. Если он не работает сейчас, попытайтесь запустить его позже. 
## Использование RongoScript в коде
Вот краткий пример использования RongoScript. Мы предоставляем его только для того, чтобы дать вам представление о том, как RongoScript доступный в форме Python библиотеки, можно использовать в коде. (Обратите внимание, что показанная здесь библиотека rongoscript в настоящее время не является общедоступной.)
```python
#Creating and training a model on data found in a json file 
import rongoscript as rs
pathtojson ='path/to/training/data/file'
model = rs.create_model(training_data = pathtojson, lang = 'en')

# Using the model for getting appropriate responses to user's phrases
phrase = 'This is a user phrase.'
response = model.get_response(phrase)
```

